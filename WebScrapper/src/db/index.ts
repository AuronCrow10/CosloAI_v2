import { Pool, PoolClient } from 'pg';
import {
  ChunkWithEmbedding,
  Client,
  DbConfig,
  SearchResult,
} from '../types.js';
import { logger } from '../logger.js';
import {
  EmbeddingModel,
  getModelDimensions,
} from '../embeddings/models.js';

export class Database {
  private pool: Pool;

  constructor(config: DbConfig) {
    this.pool = new Pool({
      connectionString: config.connectionString,
    });
  }

  async init(): Promise<void> {
    const client = await this.pool.connect();
    try {
      // Check pgvector extension
      const extRes = await client.query(
        `SELECT 1 FROM pg_extension WHERE extname = 'vector'`,
      );
      if (extRes.rowCount === 0) {
        throw new Error(
          "pgvector extension is not enabled. Run `CREATE EXTENSION IF NOT EXISTS vector;`",
        );
      }

      // Check required tables exist
      const tablesRes = await client.query<{
        clients: string | null;
        small: string | null;
        large: string | null;
      }>(`
        SELECT
          to_regclass('public.clients') AS clients,
          to_regclass('public.page_chunks_small') AS small,
          to_regclass('public.page_chunks_large') AS large
      `);

      const row = tablesRes.rows[0];
      if (!row || !row.clients || !row.small || !row.large) {
        throw new Error(
          'Required tables (clients, page_chunks_small, page_chunks_large) are missing. Run migrations.',
        );
      }

      logger.info('Connected to PostgreSQL and basic schema checks passed');
    } catch (err) {
      logger.error('Failed to initialize database', err);
      throw err;
    } finally {
      client.release();
    }
  }

  async close(): Promise<void> {
    await this.pool.end();
  }

  // ---------- CLIENTS ----------

 /**
   * Fetch a client by ID, validating the embedding_model value.
   */
  async getClientById(id: string): Promise<Client | null> {
    const client = await this.pool.connect();
    try {
      const res = await client.query<{
        id: string;
        name: string;
        embedding_model: string;
        main_domain: string | null;
        created_at: Date;
      }>(
        `
        SELECT id, name, embedding_model, main_domain, created_at
        FROM clients
        WHERE id = $1
        `,
        [id],
      );

      if (res.rowCount === 0) {
        return null;
      }

      const row = res.rows[0];
      if (
        row.embedding_model !== 'text-embedding-3-small' &&
        row.embedding_model !== 'text-embedding-3-large'
      ) {
        throw new Error(
          `Client ${row.id} has unsupported embedding_model="${row.embedding_model}". ` +
            `Allowed values: "text-embedding-3-small", "text-embedding-3-large".`,
        );
      }

      const clientObj: Client = {
        id: row.id,
        name: row.name,
        embeddingModel: row.embedding_model as EmbeddingModel,
        mainDomain: row.main_domain,
        createdAt: row.created_at,
      };

      return clientObj;
    } finally {
      client.release();
    }
  }

  /**
   * Optionally: fetch client by main_domain, if you store it.
   */
  async getClientByMainDomain(domain: string): Promise<Client | null> {
    const client = await this.pool.connect();
    try {
      const res = await client.query<{
        id: string;
        name: string;
        embedding_model: string;
        main_domain: string | null;
        created_at: Date;
      }>(
        `
        SELECT id, name, embedding_model, main_domain, created_at
        FROM clients
        WHERE main_domain = $1
        `,
        [domain],
      );

      if (res.rowCount === 0) return null;

      const row = res.rows[0];
      if (
        row.embedding_model !== 'text-embedding-3-small' &&
        row.embedding_model !== 'text-embedding-3-large'
      ) {
        throw new Error(
          `Client ${row.id} has unsupported embedding_model="${row.embedding_model}".`,
        );
      }

      return {
        id: row.id,
        name: row.name,
        embeddingModel: row.embedding_model as EmbeddingModel,
        mainDomain: row.main_domain,
        createdAt: row.created_at,
      };
    } finally {
      client.release();
    }
  }


    /**
   * Create a new client. The ID is generated by Postgres via gen_random_uuid().
   * If main_domain is already used, this will throw an error with code 'DUPLICATE_MAIN_DOMAIN'.
   */
  async createClient(params: {
    name: string;
    embeddingModel: EmbeddingModel;
    mainDomain?: string | null;
  }): Promise<Client> {
    const client = await this.pool.connect();
    try {
      const res = await client.query<{
        id: string;
        name: string;
        embedding_model: string;
        main_domain: string | null;
        created_at: Date;
      }>(
        `
        INSERT INTO clients (name, embedding_model, main_domain)
        VALUES ($1, $2, $3)
        RETURNING id, name, embedding_model, main_domain, created_at
        `,
        [params.name, params.embeddingModel, params.mainDomain ?? null],
      );

      const row = res.rows[0];

      if (
        row.embedding_model !== 'text-embedding-3-small' &&
        row.embedding_model !== 'text-embedding-3-large'
      ) {
        throw new Error(
          `Client ${row.id} has unsupported embedding_model="${row.embedding_model}".`,
        );
      }

      return {
        id: row.id,
        name: row.name,
        embeddingModel: row.embedding_model as EmbeddingModel,
        mainDomain: row.main_domain,
        createdAt: row.created_at,
      };
    } catch (err: any) {
      // 23505 = unique_violation (likely idx_clients_main_domain_unique)
      if (err?.code === '23505') {
        const e = new Error('DUPLICATE_MAIN_DOMAIN');
        (e as any).code = 'DUPLICATE_MAIN_DOMAIN';
        throw e;
      }
      throw err;
    } finally {
      client.release();
    }
  }


  // ---------- PAGE CHUNKS (SMALL / LARGE) ----------

  private getTableForModel(model: EmbeddingModel): {
    tableName: string;
    dims: number;
  } {
    const dims = getModelDimensions(model);
    const tableName =
      model === 'text-embedding-3-small'
        ? 'page_chunks_small'
        : 'page_chunks_large';
    return { tableName, dims };
  }

  /**
   * Insert a chunk + embedding for a given client and model.
   * - Routes to the correct table (small/large).
   * - Validates embedding dimension.
   * - Uses global dedup via chunk_hash (UNIQUE).
   */
  async insertChunkForClient(
    clientId: string,
    model: EmbeddingModel,
    chunk: ChunkWithEmbedding,
  ): Promise<void> {
    const { tableName, dims } = this.getTableForModel(model);

    if (chunk.embedding.length !== dims) {
      throw new Error(
        `Embedding dimension mismatch: got ${chunk.embedding.length}, expected ${dims} for model "${model}".`,
      );
    }

    const client = await this.pool.connect();
    try {
      const embeddingLiteral = `[${chunk.embedding.join(',')}]`;

      const result = await client.query(
        `
        INSERT INTO ${tableName} (
          id,
          client_id,
          domain,
          url,
          chunk_index,
          chunk_text,
          chunk_hash,
          embedding
        )
        VALUES (
          gen_random_uuid(),
          $1, $2, $3, $4, $5, $6, $7::vector
        )
        ON CONFLICT (chunk_hash) DO NOTHING
        RETURNING id
        `,
        [
          clientId,
          chunk.domain,
          chunk.url,
          chunk.chunkIndex,
          chunk.text,
          chunk.chunkHash,
          embeddingLiteral,
        ],
      );

      if (result.rowCount === 0) {
        // Duplicate detected via global hash
        logger.debug(
          `Duplicate chunk (hash=${chunk.chunkHash}) detected in ${tableName}, skipping insert.`,
        );
      }
    } catch (err) {
      logger.error('Failed to insert chunk into DB', err);
      throw err;
    } finally {
      client.release();
    }
  }

  /**
   * Semantic search by client & model, optionally filtered by domain.
   *
   * For text-embedding-3-small (1536 dims):
   *   - query against page_chunks_small
   *   - use embedding <-> $N::vector
   *   - ivfflat index on vector(1536)
   *
   * For text-embedding-3-large (3072 dims):
   *   - query against page_chunks_large
   *   - use (embedding::halfvec(3072)) <-> $N::halfvec
   *   - HNSW index on (embedding::halfvec(3072))
   */
async searchClientChunks(params: {
  clientId: string;
  model: EmbeddingModel;
  queryEmbedding: number[];
  domain?: string;
  limit: number;
}): Promise<SearchResult[]> {
  const { clientId, model, queryEmbedding, domain, limit } = params;
  const { tableName, dims } = this.getTableForModel(model);

  // Sanity check sulla dimensione dell'embedding
  if (queryEmbedding.length !== dims) {
    throw new Error(
      `Query embedding dimension mismatch: got ${queryEmbedding.length}, expected ${dims} for model "${model}".`,
    );
  }

  // pgvector accetta il formato testuale "[x,y,z,...]" per vector/halfvec
  const embeddingLiteral = `[${queryEmbedding.join(',')}]`;
  const isLarge = model === 'text-embedding-3-large';

  const client = await this.pool.connect();
  try {
    let sql: string;
    let values: unknown[];

    if (domain) {
      // ðŸ”¹ Con filtro per domain
      if (isLarge) {
        // LARGE MODEL: usa halfvec per sfruttare l'indice ANN su (embedding::halfvec)
        sql = `
          SELECT
            id,
            client_id,
            domain,
            url,
            chunk_index,
            chunk_text,
            created_at,
            (embedding::halfvec) <-> $3::halfvec AS distance
          FROM ${tableName}
          WHERE client_id = $1
            AND domain = $2
          ORDER BY (embedding::halfvec) <-> $3::halfvec
          LIMIT $4
        `;
        values = [clientId, domain, embeddingLiteral, limit];
      } else {
        // SMALL MODEL: ricerca vettoriale normale su vector
        sql = `
          SELECT
            id,
            client_id,
            domain,
            url,
            chunk_index,
            chunk_text,
            created_at,
            embedding <-> $3::vector AS distance
          FROM ${tableName}
          WHERE client_id = $1
            AND domain = $2
          ORDER BY embedding <-> $3::vector
          LIMIT $4
        `;
        values = [clientId, domain, embeddingLiteral, limit];
      }
    } else {
      // ðŸ”¹ Senza filtro di domain
      if (isLarge) {
        sql = `
          SELECT
            id,
            client_id,
            domain,
            url,
            chunk_index,
            chunk_text,
            created_at,
            (embedding::halfvec) <-> $2::halfvec AS distance
          FROM ${tableName}
          WHERE client_id = $1
          ORDER BY (embedding::halfvec) <-> $2::halfvec
          LIMIT $3
        `;
        values = [clientId, embeddingLiteral, limit];
      } else {
        sql = `
          SELECT
            id,
            client_id,
            domain,
            url,
            chunk_index,
            chunk_text,
            created_at,
            embedding <-> $2::vector AS distance
          FROM ${tableName}
          WHERE client_id = $1
          ORDER BY embedding <-> $2::vector
          LIMIT $3
        `;
        values = [clientId, embeddingLiteral, limit];
      }
    }

    const res = await client.query<{
      id: string;
      client_id: string;
      domain: string;
      url: string;
      chunk_index: number;
      chunk_text: string;
      created_at: Date;
      distance: number;
    }>(sql, values);

    return res.rows.map((row) => {
      const distance = row.distance;
      // distanza bassa = piÃ¹ simile â†’ score alto
      const score = 1 / (1 + distance);

      const result: SearchResult = {
        id: row.id,
        clientId: row.client_id,
        domain: row.domain,
        url: row.url,
        chunkIndex: row.chunk_index,
        text: row.chunk_text,
        createdAt: row.created_at,
        score,
      };

      return result;
    });
  } finally {
    client.release();
  }
}


}
